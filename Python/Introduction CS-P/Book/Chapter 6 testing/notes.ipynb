{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "* Design a chart of workflow first, then pseudocode, then class chart, then code it!\n",
    "*When implementing a test, use the chart as well!!!\n",
    "* Tests show that bugs exists\n",
    "* Design A program in such way that it could be tested\n",
    "* Create a test suite that ha a probability of producing wrong answers, and does not take too long to run\n",
    "* paratition the space of all possible inputs into subsets that provide equivalent information about the correctness of the program, and then constructing a test suite that conains at least one input from each partition\n",
    "\n",
    "\n"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "* black-box testing are heuristics based on exploring paths through the specification\n",
    "* test the distinct paths\n",
    "* test arguments not of the assumed types\n",
    "* test non -scalar objects with non intended content (empty lists, singelton lists, lists containing lists)\n",
    "* test boundary (small to large) values\n",
    "* test typical values\n",
    "* test aliasing(reference) in mutable types"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "* glass-box testing are heuristics based on exploring paths through the code .\n",
    "* Look for special cases inside the code (implied cases)\n",
    "* A test-suite is path-complete if it exercises every potential path through the program.\n",
    "* Exercise both branches of all if statements\n",
    "* make sure that each except clause is executed\n",
    "* For each for loop have test cases in which\n",
    "    * The loop is not entered( e.g., if the loop is iterating over the elements of a list, make sure that it is tested on the empty list)\n",
    "    *The body of the loop is exectued exactly once\n",
    "    *The body of the loop is exectured more than once.\n",
    "* For each while loop,\n",
    "    Look at the same kinds of cases as when dealing with for loops\n",
    "    *Include test cases corresponding to all possible ways of exiting the loop. For example, for a loop starting with while len(L)>0 and not L[i] == e, find cases where the loop exits because len(l is greater than zero and cases where it exits because L[i] == e\n",
    "    For recursive functions, include test cases that cause the functio to return with no recursive calls, exactly one recursive call, and more than one recursive call."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# conducting testing\n",
    "## unit testing\n",
    "* tests whether individual units of code work properly\n",
    "## integration testing\n",
    "* tests whether the program as a whole behaves as intended.\n",
    "## Test drivers\n",
    "* simulate parts of the program that use the unit being tested\n",
    "* Set up the environment needed to invoke the program or unit to be tested\n",
    "*Invoke the program or unit to be tested with a predefined or automatically generated sequence of inputs,\n",
    "Save the results of these invocations,\n",
    "Check the acceptability of the results of the tests\n",
    "## Stubs\n",
    "* used during unit testing\n",
    "* simlulate parts of the program used y the unit being tested\n",
    "* check the reaonableness of the environment and arguments supplied by the caller (calling a function with inappropriate arguments )\n",
    "* modify arguments and global variable in a manner consistent with the specification\n",
    "*return values consistent with the specification\n",
    "* a good practice is to limit the set of arguments accepted by the stub, and create a table that contains the values to be returned for each combination of arguments to be used i the test suite.\n",
    "* "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Runtime bugs\n",
    "* Overt$\\to$ covert: an overt bug has an obious manifestation. a covert bug has no obvious manifestation,. The program may run to conclusion with no problem - other than providing an incorrect answer: many bugs fall between the two extremes, and whether or not the bug is overt, can depend upon how carefully one examines the behavior of the program.\n",
    "* Persistent $\\to$ intermittent: a persistent bug occurs every time the program is run with the same inputs. an intermittent bug occurs only some of the time, even when the program is run on the same i puts and seemingly under the same conditions.\n",
    "# Debugging\n",
    "* Debugging is the process of searcihng for an explanation when a program behaves in undesirable ways. \n",
    "* Defensive programming is a practive of writing porgrams in such way that bugs are both overt and persistent\n",
    "* When a bug is found, ask yourself if this bug explains all the observed symptoms, or whther itis just the tip of the iceberg. If the latter, it may be better to think about taking care of this bug in concert with other changes. If so, document it with a suggested edit.\n",
    "* Before making any change, try and understand the remification of the proposed \"fix\". Wll it break something else? Does it introduce excessive complexity? Does it offer the opportunity to tidy up other parts of the code?\n",
    "* Always document bugs, the process of debugging and fixing, and the changelog in a notebook (Jupyter) by date and time\n",
    "### Workflow:\n",
    "1) examine available data: test results and program text. study also tests that passed, compare different tests\n",
    "2) form a hypothesis that you believe to be consistent with all the data such as \"If I change line 403 from x<y to x<=y the problem will go away\" or \"My program is not terminating because I have the wrong exit condition in some while loop.\"\n",
    "3)design and run a repeatable experiment with the potential to refute the hypothesis. For example put a print statement before and after each while loop. If these are always paired, then the hypothesis that a while loop is caugin nontemrination has been refuted.\n",
    "4) decide before running the experiment how you would interpret various possible results. If you wait until after you run the experiment, you are more likely tof fall prey to wishful thinking\n",
    "5) Keep a record (use Jupyter) of what experiments you tried. When youv'e spent many hours changing your code trying to track down an elusive bug, it's easy to forget what you have already tried. If you aren't careful, it is easy to waste way too many hours trying the same experiment or more likely an experiment that liiks different but will give you the same information).\n",
    "## Designing the Experiment\n",
    "* should be specific to a region of code.\n",
    "* in large code bisection search approach might help. find a point about halfwa through the code and devise an experiment that will allow you to decide if there is a problem before that point that might be related to the symptom.\n",
    "* each experiment is focused on one problem\n",
    "* look for a place where there are some esily examined intermediate values that provide usefyl information.\n",
    "* if an intermediate value is not what you expected, there is probably a problem that occured prior to that point in the code.\n",
    "* if the intermediate values all look fine, the bug probably lies somewhere later in the code. This process can be repeated until you have narorowed the reguion in which a problem is located to a few lines of code\n",
    "## Common pitfalls\n",
    "    * Passing arguments to a function in the wrong order\n",
    "    * Name\\case misspelling\n",
    "    * Failed to initialize a variable\n",
    "    * Testing floating point quality instead of near equality (using epsilon)\n",
    "    * Test for value equality insted of object equality(identical with id() function)\n",
    "    * Function side effect\n",
    "    * confused function reference func with function invocation func()\n",
    "    * Creation of unintented alias\n",
    "    * Made typical mistakes\n",
    "* Ask why the program is doing what it is.\n",
    "* Keep in mind that the bug is probably not where you think it is\n",
    "* Try to explain the problem to someone else (stackoverflow)\n",
    "* Write documentation\n"
   ]
  }
 ]
}