{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "Page 306 Tuples"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-60.5"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "def sumall(*args):\n",
    "    sum = 0\n",
    "    for arg in args:\n",
    "        sum += arg\n",
    "    return sum\n",
    "\n",
    "sumall(1,2,3,4,7.5,-78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('A', 'a', 1)\n('B', 'b', 2)\n('C', 'c', 3)\n('D', 'd', 4)\n('E', 'e', 5)\n('F', 'f', 6)\n('G', 'g', 7)\n('H', 'h', 8)\n('I', 'i', 9)\n('J', 'j', 10)\n('K', 'k', 11)\n('L', 'l', 12)\n('M', 'm', 13)\n('N', 'n', 14)\n('O', 'o', 15)\n('P', 'p', 16)\n('Q', 'q', 17)\n('R', 'r', 18)\n('S', 's', 19)\n('T', 't', 20)\n('U', 'u', 21)\n('V', 'v', 22)\n('W', 'w', 23)\n('X', 'x', 24)\n('Y', 'y', 25)\n('Z', 'z', 26)\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "nums = []\n",
    "for i in range(1,28):\n",
    "    nums.append(i)\n",
    "z = zip(string.ascii_uppercase, string.ascii_lowercase, nums)\n",
    "for pair in z:\n",
    "    print(pair)"
   ]
  },
  {
   "source": [
    "chapter 12 exercises"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Exerciese 1"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "e\ni\na\nt\ns\nn\nr\no\nm\nl\nd\nb\ny\nv\nu\nk\ng\nf\n"
     ]
    }
   ],
   "source": [
    "def most_frequent(arg_str):\n",
    "    char_dict = {}\n",
    "    char_list = []\n",
    "    for char in arg_str:\n",
    "        if char in string.ascii_letters:\n",
    "            if char.lower() not in char_dict:\n",
    "                char_dict[char.lower()] = 1\n",
    "            else:\n",
    "                char_dict[char.lower()] += 1\n",
    "    for char in char_dict:\n",
    "        char_list.append((char_dict[char], char))\n",
    "    char_list = reversed(sorted(char_list))\n",
    "    for i, char in char_list:\n",
    "        print(char)\n",
    "\n",
    "most_frequent('My name is boris and I like to fart und vegetables')"
   ]
  },
  {
   "source": [
    "Exercise 2"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'is_header_reached' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-638063c83145>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;31m# word_list = ['carded', 'cradle', 'credal', 'reclad','stoat','toast','aspire','generating', 'greatening', 'resmelts', 'smelters', 'termless']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mword_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'words.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;31m# anagram_set('smelters', word_list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-638063c83145>\u001b[0m in \u001b[0;36mgenerate_words\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mbefore_foot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minFile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mis_header_reached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpast_header\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_foot_reached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbefore_foot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpast_header\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbefore_foot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'is_header_reached' is not defined"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def generate_words(filename):\n",
    "    pattern = re.compile('[^a-zA-Z]')\n",
    "    \n",
    "    inFile = open(filename, 'r')\n",
    "    wordlist = []\n",
    "    for line in inFile:\n",
    "            for word in line.split(' '):\n",
    "                word = re.sub(pattern, '', word.lower())\n",
    "                if len(word) > 0:\n",
    "                    wordlist.append(word)\n",
    "    print(\"  \", len(wordlist), \"words loaded.\")\n",
    "    return wordlist\n",
    "\n",
    "\n",
    "def is_anagram(word1, word2):\n",
    "    for char in word1:\n",
    "        if char not in word2: return False\n",
    "    for char in word2:\n",
    "        if char not in word1: return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def anagram_set(base_word, words_list):\n",
    "    return_set = []\n",
    "    for word in words_list:\n",
    "        if is_anagram(base_word, word): return_set.append(word)\n",
    "    return return_set\n",
    "\n",
    "\n",
    "def generate_sets(words_list):\n",
    "    def word_anagramed(word, list):\n",
    "        for anagram in list:\n",
    "            if is_anagram(word, anagram): return True\n",
    "        return False\n",
    "    return_set = []\n",
    "    anagramed = []\n",
    "    for word in word_list:\n",
    "        if word in anagramed: continue\n",
    "        an_set=anagram_set(word, words_list)\n",
    "        return_set.append(an_set)\n",
    "        anagramed.extend(an_set)\n",
    "    return return_set\n",
    "\n",
    "# word_list = ['carded', 'cradle', 'credal', 'reclad','stoat','toast','aspire','generating', 'greatening', 'resmelts', 'smelters', 'termless']\n",
    "word_list = generate_words('words.txt')\n",
    "\n",
    "# anagram_set('smelters', word_list)\n",
    "\n",
    "ansets = generate_sets(word_list)\n",
    "\n",
    "for anlist in ansets:\n",
    "    print(anlist)\n",
    "\n",
    "\n"
   ]
  }
 ]
}